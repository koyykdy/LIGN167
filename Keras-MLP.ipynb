{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, load_model  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers import LSTM, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, LSTM,TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Nadam\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "%matplotlib inline\n",
    "datapath = 'Data/NewNoise SNR neg10 101pts Pickle/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Data files can be downloaded from [here](https://drive.google.com/drive/folders/1Ygpg6PwQ9KiXTlbuUBQQffuqpjrBx97G?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/NewNoise SNR neg10 101pts Pickle/x_train.p (35000, 75) (15000, 75)\n",
      "(35000, 75) (35000,) (15000, 75) (15000,) (500, 75) (500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f854dc3d518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwWAwHCMYg28wGAzHCP8PrQhKLvD9ajUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f850a32e9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrains = sorted(glob.glob(datapath+'x_train.p')) #+ sorted(glob.glob(datapath+'x_train_VLA2_Mar25_Y*'))\n",
    "ytrains = sorted(glob.glob(datapath+'y_train.p'))# + sorted(glob.glob(datapath+'y_train_VLA2_Mar25_Y*'))\n",
    "xvals = sorted(glob.glob(datapath+'x_val.p')) #+ sorted(glob.glob(datapath+'x_test_VLA2_Mar25_Y*'))\n",
    "yvals = sorted(glob.glob(datapath+'y_val.p'))# + sorted(glob.glob(datapath+'y_test_VLA2_Mar25_Y*'))\n",
    "\n",
    "\n",
    "\n",
    "# intialize\n",
    "Kinput = pickle.load(open(xtrains[0],'rb'))\n",
    "X_training = np.empty([0,Kinput.shape[1]])\n",
    "Y_training = np.empty([0,])\n",
    "X_val = np.empty([0,Kinput.shape[1]])\n",
    "Y_val = np.empty([0,])\n",
    "X_test = pickle.load(open(datapath+'x_test.p','rb'))\n",
    "Y_test = pickle.load(open(datapath+'y_test.p','rb'))\n",
    "\n",
    "for fi in np.arange(0,len(xtrains)):\n",
    "    X_training_un = pickle.load(open(xtrains[fi],'rb'))\n",
    "    Y_training_un = pickle.load(open(ytrains[fi],'rb'))\n",
    "    X_val_un = pickle.load(open(xvals[fi],'rb'))\n",
    "    Y_val_un = pickle.load(open(yvals[fi],'rb'))\n",
    "    print(xtrains[fi], X_training_un.shape, X_val_un.shape)\n",
    "\n",
    "    X_training = np.concatenate((X_training, X_training_un), axis=0)\n",
    "    Y_training = np.concatenate((Y_training, Y_training_un), axis=0)\n",
    "    X_val = np.concatenate((X_val, X_val_un), axis=0)\n",
    "    Y_val = np.concatenate((Y_val, Y_val_un), axis=0)\n",
    "\n",
    "# Centering and Normalizing data\n",
    "X_training = X_training[Y_training<15,:]\n",
    "Y_training = Y_training[Y_training<15]\n",
    "X_val = X_val[Y_val<15,:]\n",
    "Y_val = Y_val[Y_val<15]\n",
    "X_test = X_test[Y_test<15,:]\n",
    "Y_test = Y_test[Y_test<15]\n",
    "\n",
    "mux = np.mean(X_training, axis=0)\n",
    "stdx = np.std(X_training, axis=0)\n",
    "X_training = (X_training - mux)/stdx\n",
    "X_val = (X_val - mux)/stdx\n",
    "X_test = (X_test - mux)/stdx\n",
    "\n",
    "\n",
    "print(X_training.shape, Y_training.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "plt.plot(Y_training,label='Training set')\n",
    "plt.plot(Y_val,label='Cross-Validation (CV) set')\n",
    "plt.ylabel('Range (km)')\n",
    "plt.xlabel('Sample index')\n",
    "plt.title('Train, CV, and Test Sets')\n",
    "plt.plot(Y_test,label='Test set (new ship)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(data_dim = 50):\n",
    "    input_layer = Input(shape=(data_dim,))\n",
    "    hidden_layer1 = Dense(256, activation=\"tanh\", name=\"hidden_layer1\")(input_layer)\n",
    "    batch_norm1 = BatchNormalization( name = \"batch_norm_1\")(hidden_layer1)\n",
    "    drop1 = Dropout(0.30)(batch_norm1)\n",
    "    \n",
    "    hidden_layer2 = Dense(128, activation=\"tanh\", name=\"hidden_layer2\")(drop1)\n",
    "    batch_norm2 = BatchNormalization( name = \"batch_norm_2\")(hidden_layer2)\n",
    "    drop2 = Dropout(0.30)(batch_norm2)\n",
    "    \n",
    "    hidden_layer3 = Dense(64, activation=\"relu\", name=\"hidden_layer3\")(drop2)\n",
    "    batch_norm3 = BatchNormalization( name = \"batch_norm_3\")(hidden_layer3)\n",
    "    drop3 = Dropout(0.30)(batch_norm3)\n",
    "    \n",
    "    hidden_layer4 = Dense(32, activation=\"relu\", name=\"hidden_layer4\")(drop3)\n",
    "    batch_norm4 = BatchNormalization( name = \"batch_norm_4\")(hidden_layer4)\n",
    "    drop4 = Dropout(0.30)(batch_norm4)\n",
    "    \n",
    "    hidden_layer5 = Dense(32, activation=\"relu\", name=\"hidden_layer5\")(drop4)\n",
    "    batch_norm5 = BatchNormalization( name = \"batch_norm_5\")(hidden_layer5)\n",
    "    drop5 = Dropout(0.30)(batch_norm5)\n",
    "    \n",
    "    hidden_layer6 = Dense(32, activation=\"relu\", name=\"hidden_layer6\")(drop5)\n",
    "    batch_norm6 = BatchNormalization( name = \"batch_norm_6\")(hidden_layer6)\n",
    "    drop6 = Dropout(0.30)(batch_norm6)\n",
    "    \n",
    "    output_layer = Dense(1, activation=\"linear\")(drop3)\n",
    "    model = Model(inputs = input_layer, output = output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/500\n",
      "35000/35000 [==============================] - 4s 119us/step - loss: 7.4124 - val_loss: 4.6202\n",
      "Epoch 2/500\n",
      "35000/35000 [==============================] - 4s 104us/step - loss: 4.0329 - val_loss: 2.0644\n",
      "Epoch 3/500\n",
      "35000/35000 [==============================] - 4s 100us/step - loss: 2.2780 - val_loss: 0.8881\n",
      "Epoch 4/500\n",
      "35000/35000 [==============================] - 4s 102us/step - loss: 1.6695 - val_loss: 0.6422\n",
      "Epoch 5/500\n",
      "35000/35000 [==============================] - 4s 105us/step - loss: 1.4124 - val_loss: 0.5663\n",
      "Epoch 6/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 1.2235 - val_loss: 0.4937\n",
      "Epoch 7/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 1.0762 - val_loss: 0.4330\n",
      "Epoch 8/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.9646 - val_loss: 0.3894\n",
      "Epoch 9/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.8672 - val_loss: 0.3642\n",
      "Epoch 10/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.7910 - val_loss: 0.3329\n",
      "Epoch 11/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.7368 - val_loss: 0.3090\n",
      "Epoch 12/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.6934 - val_loss: 0.2891\n",
      "Epoch 13/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.6420 - val_loss: 0.2666\n",
      "Epoch 14/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.6196 - val_loss: 0.2490\n",
      "Epoch 15/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.5816 - val_loss: 0.2408\n",
      "Epoch 16/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.5610 - val_loss: 0.2226\n",
      "Epoch 17/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.5325 - val_loss: 0.2148\n",
      "Epoch 18/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.5061 - val_loss: 0.2025\n",
      "Epoch 19/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.4878 - val_loss: 0.2002\n",
      "Epoch 20/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.4746 - val_loss: 0.1876\n",
      "Epoch 21/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.4628 - val_loss: 0.1741\n",
      "Epoch 22/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.4491 - val_loss: 0.1698\n",
      "Epoch 23/500\n",
      "35000/35000 [==============================] - 4s 100us/step - loss: 0.4366 - val_loss: 0.1678\n",
      "Epoch 24/500\n",
      "35000/35000 [==============================] - 4s 111us/step - loss: 0.4147 - val_loss: 0.1559\n",
      "Epoch 25/500\n",
      "35000/35000 [==============================] - 4s 108us/step - loss: 0.4093 - val_loss: 0.1515\n",
      "Epoch 26/500\n",
      "35000/35000 [==============================] - 3s 91us/step - loss: 0.3972 - val_loss: 0.1482\n",
      "Epoch 27/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.3899 - val_loss: 0.1414\n",
      "Epoch 28/500\n",
      "35000/35000 [==============================] - 4s 112us/step - loss: 0.3737 - val_loss: 0.1343\n",
      "Epoch 29/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.3685 - val_loss: 0.1271\n",
      "Epoch 30/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.3592 - val_loss: 0.1261\n",
      "Epoch 31/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.3504 - val_loss: 0.1230\n",
      "Epoch 32/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.3450 - val_loss: 0.1203\n",
      "Epoch 33/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.3240 - val_loss: 0.1154\n",
      "Epoch 34/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.3342 - val_loss: 0.1071\n",
      "Epoch 35/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.3251 - val_loss: 0.1072\n",
      "Epoch 36/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.3188 - val_loss: 0.1036\n",
      "Epoch 37/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.3089 - val_loss: 0.0981\n",
      "Epoch 38/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.3135 - val_loss: 0.1001\n",
      "Epoch 39/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.3033 - val_loss: 0.0943\n",
      "Epoch 40/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.3038 - val_loss: 0.0909\n",
      "Epoch 41/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.2951 - val_loss: 0.0896\n",
      "Epoch 42/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2874 - val_loss: 0.0878\n",
      "Epoch 43/500\n",
      "35000/35000 [==============================] - 3s 92us/step - loss: 0.2836 - val_loss: 0.0843\n",
      "Epoch 44/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2824 - val_loss: 0.0815\n",
      "Epoch 45/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.2808 - val_loss: 0.0794\n",
      "Epoch 46/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2753 - val_loss: 0.0785\n",
      "Epoch 47/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.2702 - val_loss: 0.0770\n",
      "Epoch 48/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2622 - val_loss: 0.0730\n",
      "Epoch 49/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.2647 - val_loss: 0.0717\n",
      "Epoch 50/500\n",
      "35000/35000 [==============================] - 3s 92us/step - loss: 0.2621 - val_loss: 0.0692\n",
      "Epoch 51/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2586 - val_loss: 0.0690\n",
      "Epoch 52/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.2539 - val_loss: 0.0654\n",
      "Epoch 53/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2490 - val_loss: 0.0658\n",
      "Epoch 54/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2462 - val_loss: 0.0634\n",
      "Epoch 55/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2458 - val_loss: 0.0638\n",
      "Epoch 56/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2421 - val_loss: 0.0607\n",
      "Epoch 57/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2427 - val_loss: 0.0593\n",
      "Epoch 58/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2426 - val_loss: 0.0586\n",
      "Epoch 59/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2423 - val_loss: 0.0576\n",
      "Epoch 60/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2356 - val_loss: 0.0591\n",
      "Epoch 61/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2339 - val_loss: 0.0545\n",
      "Epoch 62/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2293 - val_loss: 0.0575\n",
      "Epoch 63/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2235 - val_loss: 0.0549\n",
      "Epoch 64/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2295 - val_loss: 0.0527\n",
      "Epoch 65/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2291 - val_loss: 0.0514\n",
      "Epoch 66/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2281 - val_loss: 0.0506\n",
      "Epoch 67/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2234 - val_loss: 0.0528\n",
      "Epoch 68/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2217 - val_loss: 0.0503\n",
      "Epoch 69/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2134 - val_loss: 0.0487\n",
      "Epoch 70/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.2199 - val_loss: 0.0449\n",
      "Epoch 71/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.2148 - val_loss: 0.0477\n",
      "Epoch 72/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2177 - val_loss: 0.0470\n",
      "Epoch 73/500\n",
      "35000/35000 [==============================] - 4s 100us/step - loss: 0.2145 - val_loss: 0.0495\n",
      "Epoch 74/500\n",
      "35000/35000 [==============================] - 4s 109us/step - loss: 0.2128 - val_loss: 0.0468\n",
      "Epoch 75/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.2156 - val_loss: 0.0456\n",
      "Epoch 76/500\n",
      "35000/35000 [==============================] - 4s 102us/step - loss: 0.2104 - val_loss: 0.0438\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000/35000 [==============================] - 4s 113us/step - loss: 0.2098 - val_loss: 0.0466\n",
      "Epoch 78/500\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 0.2070 - val_loss: 0.0436\n",
      "Epoch 79/500\n",
      "35000/35000 [==============================] - 4s 122us/step - loss: 0.2106 - val_loss: 0.0467\n",
      "Epoch 80/500\n",
      "35000/35000 [==============================] - 4s 119us/step - loss: 0.2034 - val_loss: 0.0464\n",
      "Epoch 81/500\n",
      "35000/35000 [==============================] - 4s 114us/step - loss: 0.2046 - val_loss: 0.0436\n",
      "Epoch 82/500\n",
      "35000/35000 [==============================] - 4s 112us/step - loss: 0.2053 - val_loss: 0.0429\n",
      "Epoch 83/500\n",
      "35000/35000 [==============================] - 4s 113us/step - loss: 0.2042 - val_loss: 0.0426\n",
      "Epoch 84/500\n",
      "35000/35000 [==============================] - 4s 106us/step - loss: 0.2011 - val_loss: 0.0435\n",
      "Epoch 85/500\n",
      "35000/35000 [==============================] - 4s 101us/step - loss: 0.2033 - val_loss: 0.0447\n",
      "Epoch 86/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1963 - val_loss: 0.0408\n",
      "Epoch 87/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1994 - val_loss: 0.0401\n",
      "Epoch 88/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1974 - val_loss: 0.0388\n",
      "Epoch 89/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1918 - val_loss: 0.0400\n",
      "Epoch 90/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1966 - val_loss: 0.0402\n",
      "Epoch 91/500\n",
      "35000/35000 [==============================] - 4s 103us/step - loss: 0.1951 - val_loss: 0.0406\n",
      "Epoch 92/500\n",
      "35000/35000 [==============================] - 4s 103us/step - loss: 0.1991 - val_loss: 0.0402\n",
      "Epoch 93/500\n",
      "35000/35000 [==============================] - 4s 101us/step - loss: 0.1905 - val_loss: 0.0376\n",
      "Epoch 94/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1914 - val_loss: 0.0373\n",
      "Epoch 95/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1912 - val_loss: 0.0372\n",
      "Epoch 96/500\n",
      "35000/35000 [==============================] - 4s 102us/step - loss: 0.1906 - val_loss: 0.0379\n",
      "Epoch 97/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1877 - val_loss: 0.0383\n",
      "Epoch 98/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1887 - val_loss: 0.0360\n",
      "Epoch 99/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1935 - val_loss: 0.0372\n",
      "Epoch 100/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1856 - val_loss: 0.0388\n",
      "Epoch 101/500\n",
      "35000/35000 [==============================] - 4s 100us/step - loss: 0.1857 - val_loss: 0.0355\n",
      "Epoch 102/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1860 - val_loss: 0.0355\n",
      "Epoch 103/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1865 - val_loss: 0.0356\n",
      "Epoch 104/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1867 - val_loss: 0.0386\n",
      "Epoch 105/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1857 - val_loss: 0.0382\n",
      "Epoch 106/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1818 - val_loss: 0.0341\n",
      "Epoch 107/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1813 - val_loss: 0.0361\n",
      "Epoch 108/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1861 - val_loss: 0.0369\n",
      "Epoch 109/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1846 - val_loss: 0.0328\n",
      "Epoch 110/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1826 - val_loss: 0.0355\n",
      "Epoch 111/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1830 - val_loss: 0.0359\n",
      "Epoch 112/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1784 - val_loss: 0.0368\n",
      "Epoch 113/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1798 - val_loss: 0.0350\n",
      "Epoch 114/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1763 - val_loss: 0.0385\n",
      "Epoch 115/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1775 - val_loss: 0.0348\n",
      "Epoch 116/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1740 - val_loss: 0.0323\n",
      "Epoch 117/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1783 - val_loss: 0.0363\n",
      "Epoch 118/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1819 - val_loss: 0.0320\n",
      "Epoch 119/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1769 - val_loss: 0.0345\n",
      "Epoch 120/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1768 - val_loss: 0.0339\n",
      "Epoch 121/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1715 - val_loss: 0.0328\n",
      "Epoch 122/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1723 - val_loss: 0.0351\n",
      "Epoch 123/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1770 - val_loss: 0.0314\n",
      "Epoch 124/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1755 - val_loss: 0.0332\n",
      "Epoch 125/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1713 - val_loss: 0.0336\n",
      "Epoch 126/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1690 - val_loss: 0.0325\n",
      "Epoch 127/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1721 - val_loss: 0.0305\n",
      "Epoch 128/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1713 - val_loss: 0.0351\n",
      "Epoch 129/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1717 - val_loss: 0.0317\n",
      "Epoch 130/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1723 - val_loss: 0.0300\n",
      "Epoch 131/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1680 - val_loss: 0.0323\n",
      "Epoch 132/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1714 - val_loss: 0.0308\n",
      "Epoch 133/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1728 - val_loss: 0.0313\n",
      "Epoch 134/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1683 - val_loss: 0.0316\n",
      "Epoch 135/500\n",
      "35000/35000 [==============================] - 3s 100us/step - loss: 0.1663 - val_loss: 0.0313\n",
      "Epoch 136/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1669 - val_loss: 0.0292\n",
      "Epoch 137/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1671 - val_loss: 0.0299\n",
      "Epoch 138/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1676 - val_loss: 0.0332\n",
      "Epoch 139/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1648 - val_loss: 0.0327\n",
      "Epoch 140/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1650 - val_loss: 0.0297\n",
      "Epoch 141/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1652 - val_loss: 0.0315\n",
      "Epoch 142/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1664 - val_loss: 0.0310\n",
      "Epoch 143/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1665 - val_loss: 0.0310\n",
      "Epoch 144/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1592 - val_loss: 0.0296\n",
      "Epoch 145/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1637 - val_loss: 0.0288\n",
      "Epoch 146/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1625 - val_loss: 0.0297\n",
      "Epoch 147/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1624 - val_loss: 0.0312\n",
      "Epoch 148/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1625 - val_loss: 0.0286\n",
      "Epoch 149/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1589 - val_loss: 0.0308\n",
      "Epoch 150/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1577 - val_loss: 0.0308\n",
      "Epoch 151/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1564 - val_loss: 0.0311\n",
      "Epoch 152/500\n",
      "35000/35000 [==============================] - 3s 93us/step - loss: 0.1626 - val_loss: 0.0276\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1635 - val_loss: 0.0304\n",
      "Epoch 154/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1573 - val_loss: 0.0307\n",
      "Epoch 155/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1602 - val_loss: 0.0296\n",
      "Epoch 156/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1601 - val_loss: 0.0291\n",
      "Epoch 157/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1576 - val_loss: 0.0281\n",
      "Epoch 158/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1563 - val_loss: 0.0291\n",
      "Epoch 159/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1575 - val_loss: 0.0313\n",
      "Epoch 160/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1624 - val_loss: 0.0273\n",
      "Epoch 161/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1563 - val_loss: 0.0280\n",
      "Epoch 162/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1568 - val_loss: 0.0275\n",
      "Epoch 163/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1527 - val_loss: 0.0286\n",
      "Epoch 164/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1539 - val_loss: 0.0305\n",
      "Epoch 165/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1569 - val_loss: 0.0272\n",
      "Epoch 166/500\n",
      "35000/35000 [==============================] - 4s 110us/step - loss: 0.1542 - val_loss: 0.0286\n",
      "Epoch 167/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1524 - val_loss: 0.0262\n",
      "Epoch 168/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1531 - val_loss: 0.0275\n",
      "Epoch 169/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1581 - val_loss: 0.0285\n",
      "Epoch 170/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1573 - val_loss: 0.0270\n",
      "Epoch 171/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1519 - val_loss: 0.0261\n",
      "Epoch 172/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1541 - val_loss: 0.0261\n",
      "Epoch 173/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1490 - val_loss: 0.0281\n",
      "Epoch 174/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1524 - val_loss: 0.0273\n",
      "Epoch 175/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1527 - val_loss: 0.0288\n",
      "Epoch 176/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1511 - val_loss: 0.0267\n",
      "Epoch 177/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1463 - val_loss: 0.0278\n",
      "Epoch 178/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1506 - val_loss: 0.0274\n",
      "Epoch 179/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1434 - val_loss: 0.0257\n",
      "Epoch 180/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1506 - val_loss: 0.0265\n",
      "Epoch 181/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1466 - val_loss: 0.0265\n",
      "Epoch 182/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1510 - val_loss: 0.0278\n",
      "Epoch 183/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1481 - val_loss: 0.0262\n",
      "Epoch 184/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1488 - val_loss: 0.0265\n",
      "Epoch 185/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1459 - val_loss: 0.0271\n",
      "Epoch 186/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1513 - val_loss: 0.0259\n",
      "Epoch 187/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1450 - val_loss: 0.0239\n",
      "Epoch 188/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1462 - val_loss: 0.0254\n",
      "Epoch 189/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1485 - val_loss: 0.0262\n",
      "Epoch 190/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1425 - val_loss: 0.0254\n",
      "Epoch 191/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1448 - val_loss: 0.0255\n",
      "Epoch 192/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1447 - val_loss: 0.0271\n",
      "Epoch 193/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1464 - val_loss: 0.0251\n",
      "Epoch 194/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1490 - val_loss: 0.0258\n",
      "Epoch 195/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1408 - val_loss: 0.0236\n",
      "Epoch 196/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1407 - val_loss: 0.0238\n",
      "Epoch 197/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1393 - val_loss: 0.0236\n",
      "Epoch 198/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1459 - val_loss: 0.0266\n",
      "Epoch 199/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1407 - val_loss: 0.0250\n",
      "Epoch 200/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1422 - val_loss: 0.0257\n",
      "Epoch 201/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1470 - val_loss: 0.0267\n",
      "Epoch 202/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1423 - val_loss: 0.0258\n",
      "Epoch 203/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1446 - val_loss: 0.0259\n",
      "Epoch 204/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1397 - val_loss: 0.0268\n",
      "Epoch 205/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1398 - val_loss: 0.0254\n",
      "Epoch 206/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1411 - val_loss: 0.0263\n",
      "Epoch 207/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1352 - val_loss: 0.0243\n",
      "Epoch 208/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1392 - val_loss: 0.0246\n",
      "Epoch 209/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1385 - val_loss: 0.0243\n",
      "Epoch 210/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1392 - val_loss: 0.0246\n",
      "Epoch 211/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1377 - val_loss: 0.0246\n",
      "Epoch 212/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1408 - val_loss: 0.0243\n",
      "Epoch 213/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1374 - val_loss: 0.0229\n",
      "Epoch 214/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1369 - val_loss: 0.0237\n",
      "Epoch 215/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1379 - val_loss: 0.0242\n",
      "Epoch 216/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1358 - val_loss: 0.0225\n",
      "Epoch 217/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1383 - val_loss: 0.0233\n",
      "Epoch 218/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1372 - val_loss: 0.0241\n",
      "Epoch 219/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1343 - val_loss: 0.0241\n",
      "Epoch 220/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1328 - val_loss: 0.0248\n",
      "Epoch 221/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1346 - val_loss: 0.0247\n",
      "Epoch 222/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1390 - val_loss: 0.0246\n",
      "Epoch 223/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1380 - val_loss: 0.0237\n",
      "Epoch 224/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1372 - val_loss: 0.0250\n",
      "Epoch 225/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1386 - val_loss: 0.0242\n",
      "Epoch 226/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1332 - val_loss: 0.0236\n",
      "Epoch 227/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1324 - val_loss: 0.0229\n",
      "Epoch 228/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1334 - val_loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1351 - val_loss: 0.0244\n",
      "Epoch 230/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1349 - val_loss: 0.0226\n",
      "Epoch 231/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1350 - val_loss: 0.0235\n",
      "Epoch 232/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1336 - val_loss: 0.0239\n",
      "Epoch 233/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1375 - val_loss: 0.0238\n",
      "Epoch 234/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1335 - val_loss: 0.0249\n",
      "Epoch 235/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1346 - val_loss: 0.0230\n",
      "Epoch 236/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1365 - val_loss: 0.0219\n",
      "Epoch 237/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1327 - val_loss: 0.0213\n",
      "Epoch 238/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1343 - val_loss: 0.0228\n",
      "Epoch 239/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1357 - val_loss: 0.0228\n",
      "Epoch 240/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1343 - val_loss: 0.0226\n",
      "Epoch 241/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1344 - val_loss: 0.0221\n",
      "Epoch 242/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1290 - val_loss: 0.0217\n",
      "Epoch 243/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1316 - val_loss: 0.0212\n",
      "Epoch 244/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1259 - val_loss: 0.0246\n",
      "Epoch 245/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1322 - val_loss: 0.0235\n",
      "Epoch 246/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1310 - val_loss: 0.0223\n",
      "Epoch 247/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1324 - val_loss: 0.0223\n",
      "Epoch 248/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1270 - val_loss: 0.0232\n",
      "Epoch 249/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1293 - val_loss: 0.0221\n",
      "Epoch 250/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1303 - val_loss: 0.0214\n",
      "Epoch 251/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1283 - val_loss: 0.0206\n",
      "Epoch 252/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1301 - val_loss: 0.0229\n",
      "Epoch 253/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1299 - val_loss: 0.0233\n",
      "Epoch 254/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1312 - val_loss: 0.0223\n",
      "Epoch 255/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1300 - val_loss: 0.0213\n",
      "Epoch 256/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1311 - val_loss: 0.0221\n",
      "Epoch 257/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1275 - val_loss: 0.0224\n",
      "Epoch 258/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1310 - val_loss: 0.0230\n",
      "Epoch 259/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1239 - val_loss: 0.0233\n",
      "Epoch 260/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1290 - val_loss: 0.0227\n",
      "Epoch 261/500\n",
      "35000/35000 [==============================] - 3s 94us/step - loss: 0.1268 - val_loss: 0.0212\n",
      "Epoch 262/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1326 - val_loss: 0.0228\n",
      "Epoch 263/500\n",
      "35000/35000 [==============================] - 4s 108us/step - loss: 0.1346 - val_loss: 0.0218\n",
      "Epoch 264/500\n",
      "35000/35000 [==============================] - 4s 100us/step - loss: 0.1280 - val_loss: 0.0210\n",
      "Epoch 265/500\n",
      "35000/35000 [==============================] - 4s 101us/step - loss: 0.1300 - val_loss: 0.0221\n",
      "Epoch 266/500\n",
      "35000/35000 [==============================] - 4s 112us/step - loss: 0.1278 - val_loss: 0.0218\n",
      "Epoch 267/500\n",
      "35000/35000 [==============================] - 4s 120us/step - loss: 0.1238 - val_loss: 0.0215\n",
      "Epoch 268/500\n",
      "35000/35000 [==============================] - 4s 121us/step - loss: 0.1263 - val_loss: 0.0210\n",
      "Epoch 269/500\n",
      "35000/35000 [==============================] - 4s 115us/step - loss: 0.1215 - val_loss: 0.0216\n",
      "Epoch 270/500\n",
      "35000/35000 [==============================] - 4s 115us/step - loss: 0.1257 - val_loss: 0.0224\n",
      "Epoch 271/500\n",
      "35000/35000 [==============================] - 4s 112us/step - loss: 0.1277 - val_loss: 0.0217\n",
      "Epoch 272/500\n",
      "35000/35000 [==============================] - 4s 115us/step - loss: 0.1242 - val_loss: 0.0209\n",
      "Epoch 273/500\n",
      "35000/35000 [==============================] - 4s 104us/step - loss: 0.1314 - val_loss: 0.0203\n",
      "Epoch 274/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1273 - val_loss: 0.0203\n",
      "Epoch 275/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1299 - val_loss: 0.0210\n",
      "Epoch 276/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1247 - val_loss: 0.0210\n",
      "Epoch 277/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1278 - val_loss: 0.0220\n",
      "Epoch 278/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1275 - val_loss: 0.0218\n",
      "Epoch 279/500\n",
      "35000/35000 [==============================] - 3s 99us/step - loss: 0.1252 - val_loss: 0.0218\n",
      "Epoch 280/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1246 - val_loss: 0.0192\n",
      "Epoch 281/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1257 - val_loss: 0.0212\n",
      "Epoch 282/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1237 - val_loss: 0.0217\n",
      "Epoch 283/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1265 - val_loss: 0.0197\n",
      "Epoch 284/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1242 - val_loss: 0.0200\n",
      "Epoch 285/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1225 - val_loss: 0.0213\n",
      "Epoch 286/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1268 - val_loss: 0.0207\n",
      "Epoch 287/500\n",
      "35000/35000 [==============================] - 3s 95us/step - loss: 0.1285 - val_loss: 0.0205\n",
      "Epoch 288/500\n",
      "35000/35000 [==============================] - 4s 101us/step - loss: 0.1244 - val_loss: 0.0207\n",
      "Epoch 289/500\n",
      "35000/35000 [==============================] - 4s 106us/step - loss: 0.1260 - val_loss: 0.0197\n",
      "Epoch 290/500\n",
      "35000/35000 [==============================] - 3s 97us/step - loss: 0.1224 - val_loss: 0.0198\n",
      "Epoch 291/500\n",
      "35000/35000 [==============================] - 3s 96us/step - loss: 0.1236 - val_loss: 0.0207\n",
      "Epoch 292/500\n",
      "35000/35000 [==============================] - 4s 114us/step - loss: 0.1237 - val_loss: 0.0200\n",
      "Epoch 293/500\n",
      "35000/35000 [==============================] - 4s 117us/step - loss: 0.1264 - val_loss: 0.0214\n",
      "Epoch 294/500\n",
      "35000/35000 [==============================] - 4s 120us/step - loss: 0.1240 - val_loss: 0.0206\n",
      "Epoch 295/500\n",
      "35000/35000 [==============================] - 4s 118us/step - loss: 0.1242 - val_loss: 0.0211\n",
      "Epoch 296/500\n",
      "35000/35000 [==============================] - 4s 110us/step - loss: 0.1234 - val_loss: 0.0192\n",
      "Epoch 297/500\n",
      "35000/35000 [==============================] - 4s 115us/step - loss: 0.1218 - val_loss: 0.0206\n",
      "Epoch 298/500\n",
      "35000/35000 [==============================] - 4s 114us/step - loss: 0.1258 - val_loss: 0.0192\n",
      "Epoch 299/500\n",
      "35000/35000 [==============================] - 4s 103us/step - loss: 0.1209 - val_loss: 0.0191\n",
      "Epoch 300/500\n",
      "35000/35000 [==============================] - 3s 98us/step - loss: 0.1224 - val_loss: 0.0201\n",
      "Epoch 301/500\n",
      "26600/35000 [=====================>........] - ETA: 0s - loss: 0.1281"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "data_dim = X_training.shape[1]\n",
    "optimizer = optimizers.RMSprop(lr=1e-4)#, beta_1=0.9, beta_2=0.999, epsilon=1e-08)#, schedule_decay=0.004)\n",
    "model = get_model(data_dim)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "batch_size = 50\n",
    "L=len(X_training)\n",
    "val_data = (X_val, Y_val)\n",
    "history = model.fit(X_training, Y_training, batch_size=batch_size, epochs=n_epochs, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "preds2 = model.predict(X_training)\n",
    "preds3 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "plt.plot(preds2,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_training,'y',linewidth=1.0)\n",
    "#plt.legend(['Training Set', 'Ground Truth'])\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Range (km)')\n",
    "plt.title('Training')\n",
    "\n",
    "RMSE_Ytrain = np.sqrt(np.mean(np.square(np.abs(Y_training-preds2[:,0]))))\n",
    "\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(preds,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_val,'r',linewidth=1.0)\n",
    "#plt.legend(['Predictions', 'Ground Truth'])\n",
    "plt.xlabel('Sample index')\n",
    "#plt.ylabel('Range (km)')\n",
    "plt.title('Validation')\n",
    "\n",
    "RMSE_Yval = np.mean(np.abs(Y_val-preds[:,0]))\n",
    "\n",
    "#plt.subplot(133)\n",
    "plt.figure()\n",
    "plt.plot(preds3,'o',color='blue',markersize=2,mew=0.5,mec='blue',markerfacecolor='none')\n",
    "plt.plot(Y_test,'r',linewidth=1.0)\n",
    "#plt.plot(Y_training,'y',linewidth=1.0)\n",
    "plt.legend(['Predictions', 'Ground Truth'])\n",
    "plt.xlabel('Sample index')\n",
    "#plt.ylabel('Range (km)')\n",
    "plt.title('Test (unseen ship)')\n",
    "plt.savefig('test_noisy_simulation.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "RMSE_Ytest = np.sqrt(np.mean(np.square(np.abs(Y_test-preds3[:,0]))))\n",
    "\n",
    "MAE = np.mean(np.abs(Y_test-preds3[:,0])/Y_test)\n",
    "print('Mean relative error' + str(MAE))\n",
    "\n",
    "print('Training set RMSE = ' + str(RMSE_Ytrain) + ' km')\n",
    "print('Validation set RMSE = ' + str(RMSE_Yval) + ' km')\n",
    "print('Test set RMSE = ' + str(RMSE_Ytest) + ' km')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('model_mlp.h5')\n",
    "\n",
    "# # Load saved model\n",
    "# model = load_model('model_mlp.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "k=0\n",
    "for i in range(len(weights)):\n",
    "    shape = weights[i].shape\n",
    "    if(len(shape)>1):\n",
    "        fileName = \"mlp_weights_layer_{}.png\".format(k)\n",
    "        plt.figure()\n",
    "        if((shape[0]>1) & (shape[1]>1)):\n",
    "            plt.imshow(np.abs(weights[i]))\n",
    "            plt.colorbar()\n",
    "        else:\n",
    "            plt.plot(np.abs(weights[i]))   \n",
    "       # plt.savefig(fileName)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    \n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_num = 0\n",
    "activation_map = get_activations(model, np.reshape(X_test[test_sample_num,:], (1, X_test.shape[1])))\n",
    "layers = [0, 3]#, 6, 9, 10]\n",
    "print(activation_map[3].shape)\n",
    "\n",
    "for key, layer in enumerate(layers):\n",
    "    \n",
    "    activations = activation_map[layer][0]\n",
    "    subplot_num = len(layers)*100 + 1*10 + key+1\n",
    "    plt.subplot(subplot_num)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    plt.imshow(np.reshape(activations, (1, len(activations))), interpolation = 'nearest', aspect='auto')\n",
    "cax = plt.axes([1, 0.1, 0.075, 0.8])\n",
    "plt.tight_layout()\n",
    "plt.colorbar(cax=cax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
